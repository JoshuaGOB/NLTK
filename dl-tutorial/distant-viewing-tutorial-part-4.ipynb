{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distant Viewing with Deep Learning: Part 4\n",
    "\n",
    "In Part 4 of this tutorial, we extend deep learning models to deal with\n",
    "a specific type of object detection: the localization and identification\n",
    "of faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Python modules for face detection\n",
    "\n",
    "We need to reload all of the Python modules we used in the Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import os\n",
    "from os.path import join\n",
    "from matplotlib.colors import rgb_to_hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load and look at the third corpus we have provided. It contains still images from\n",
    "two episodes of the sit-com Bewitched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bewitched = pd.read_csv(\"meta/bewitched.csv\")\n",
    "bewitched.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the code in this notebook from scratch, you will also need the **face_recognition**\n",
    "module for working with neural networks. This are not included in the default\n",
    "Anaconda Python installation and need to be installed seperately. The code\n",
    "below checks if you have **face_recognition** installed. If you do, it will be\n",
    "loaded. Otherwise, a flag will be set so that the code below that requires the\n",
    "module will load the\n",
    "pre-loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if importlib.util.find_spec(\"face_recognition\") is not None:\n",
    "    import face_recognition as fr\n",
    "    fr_flag = True\n",
    "else:\n",
    "    fr_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are struggling with installing these, we are happy to assist. You'll be able to follow\n",
    "along with keras, but will not be able to apply the techniques you learned today to new datasets\n",
    "without it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Face detection\n",
    "\n",
    "Our last set of steps concern the location and identification of faces in an image.\n",
    "While faces are particularly interesting, similar models exist for detecting the\n",
    "location of other objects using neural networks.\n",
    "\n",
    "As an example of what this new corpus looks like, here is an image of Darrin and Samantha\n",
    "in their living room at the start of the episode \"Witches and Warlocks Are my Favorite\n",
    "Things\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = join('images', 'bewitched', bewitched.iloc[200]['filename'])\n",
    "img = imread(img_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two faces in this image, which we can detect using the face_recognition\n",
    "algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fr_flag:\n",
    "    faces = fr.face_locations(img, 1, model=\"cnn\")\n",
    "else:\n",
    "    faces = [(172, 500, 254, 418), (81, 346, 179, 248)]\n",
    "    \n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output indicates that two faces are detected, and the numbers gives the\n",
    "coordinates for the faces known as *bounding boxes*. We can plot them in Python\n",
    "with the following snippet of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "plt.imshow(img)\n",
    "n, m, d = img.shape\n",
    "for face in faces:\n",
    "    rect = plt.Rectangle((face[3], face[0]), face[2] - face[0], face[1] - face[3],\n",
    "                         edgecolor='orange', linewidth=2, facecolor='none')\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as hoped, the detected faces line up with the two characters in the frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15: Face identification\n",
    "\n",
    "In addition to detected *where* a face is, we also want to determine *who* the face\n",
    "belongs to. In order to do this, we again make use of a pre-trained neural network\n",
    "that returns a sequence of numbers. Just as in Step 11 with image similarity, we\n",
    "assume that faces of the same person are identified with similar sequences of numbers.\n",
    "\n",
    "To illustrate how this works, lets take a set of four faces from Bewitched. The first\n",
    "two are of the same character (Samantha) but the second two are of of Larry and Darrin,\n",
    "respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "for id, index in enumerate([145, 300, 420, 707]):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(1, 4, id + 1)\n",
    "\n",
    "    img_path = join('images', 'bewitched', bewitched.iloc[index]['filename'])\n",
    "    img = imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the 128-dimension number associated with each face using the function\n",
    "`fr.face_encodings` applied to each face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fr_flag:\n",
    "    embed = []\n",
    "    for id, index in enumerate([300, 145, 420, 707]):\n",
    "        img_path = join('images', 'bewitched', bewitched.iloc[index]['filename'])\n",
    "        img = imread(img_path)\n",
    "\n",
    "        f = fr.face_locations(img, 1, model=\"cnn\")\n",
    "        e = fr.face_encodings(img, known_face_locations=[f[0]])\n",
    "        embed.append(e[0])\n",
    "else:\n",
    "    embed = np.load(join('data', 'face_test.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the first image of Samantha as a baseline, look at how close each of the other three\n",
    "images are to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = np.array(embed)\n",
    "np.sum((embed - embed[0, :])**2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other image of Samantha is just 0.202 away but the images of the two male characters\n",
    "are 0.709 and 0.710 away. Using a cut-off (around 0.35 works well), we can identify images\n",
    "of Samantha with a reasonably high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 16: Faces at scale\n",
    "\n",
    "Finally, let's apply our face detection algorithm of the entire corpus of Bewitched\n",
    "iamges. The face detect is fairly slow (it took about 30 minutes on my small MacBook\n",
    "to do all of the images), so we recommend you set `process_new` to `False` and load\n",
    "the faces in from the save file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_new = False\n",
    "\n",
    "if process_new:\n",
    "    embed = []; output = []\n",
    "    corpus = pd.read_csv(join(\"meta\", cn + \".csv\"))\n",
    "    for index, row in corpus.iterrows():\n",
    "        img_path = join('images', cn, row['filename'])\n",
    "        img = sp.misc.imread(img_path)\n",
    "        faces = fr.face_locations(img, 1, model=\"cnn\")\n",
    "        output.append(faces)\n",
    "        enc = fr.face_encodings(img, known_face_locations=faces)\n",
    "        embed.append(enc)\n",
    "else:\n",
    "    faces = np.load(join(\"data\", \"bewitched_faces.npy\"))\n",
    "    embed = np.load(join(\"data\", \"bewitched_embed.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compare each of the embeddings to first image used in Step 13, storing the\n",
    "distance in the array `samantha_dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samantha = embed[145][0]\n",
    "\n",
    "samantha_dist = np.ones(bewitched.shape[0])\n",
    "for item in range(embed.shape[0]):\n",
    "    for em in embed[item]:\n",
    "        samantha_dist[item] = np.sum((samantha - em)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cut-off of 0.35, how many frames contain an image of Samantha?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(samantha_dist < 0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a total of 119 images show a definitive image of Samantha. Using a similar\n",
    "block of code to the similarity metrics used throughout these notes, what images contain\n",
    "the most similar Samantha faces to our prototype image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 24))\n",
    "\n",
    "sam_index = np.argsort(samantha_dist).tolist()\n",
    "for ind, i in enumerate(sam_index[:24]):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(8, 3, ind + 1)\n",
    "\n",
    "    img_path = join('images', 'bewitched', bewitched.iloc[i]['filename'])\n",
    "    img = imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like our prototype, almost all of these indicates a relatively large view of Samantha looking\n",
    "straight at the camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, use image 707 as a baseline for Darrin and compute a darrin_distance metric for\n",
    "each image**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darrin = embed[707][0]\n",
    "\n",
    "darrin_dist = np.ones(bewitched.shape[0])\n",
    "for item in range(embed.shape[0]):\n",
    "    for em in embed[item]:\n",
    "        darrin_dist[item] = np.sum((darrin - em)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then, display the top 24 images of Darrin.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 24))\n",
    "\n",
    "darrin_index = np.argsort(darrin_dist).tolist()\n",
    "for ind, i in enumerate(darrin_index[:24]):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    plt.subplot(8, 3, ind + 1)\n",
    "\n",
    "    img_path = join('images', 'bewitched', bewitched.iloc[i]['filename'])\n",
    "    img = imread(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do these compare to those of Samantha?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
