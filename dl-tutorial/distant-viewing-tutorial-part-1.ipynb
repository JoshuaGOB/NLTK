{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distant Viewing with Deep Learning: Part 1\n",
    "\n",
    "This tutorial provides a hands-on introduction to the use of deep learning\n",
    "techniques in the study of large image corpora. The TensorFlow and Keras\n",
    "libraries within the Python programming language are used to facilitate this\n",
    "analysis. No prior programming experience is required.\n",
    "\n",
    "If you are seeing this text, you must have already downloaded Python and the\n",
    "data files. Currently, you are running an *IPython notebook*. This is a document\n",
    "that runs Python in your browser and provides space for integrating text (like\n",
    "this) and code (below!). The format of this tutorial involves a mixture of running\n",
    "code that we have provided and copying/writing your own code. Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Code of conduct\n",
    "\n",
    "In order for this tutorial to be successful, we ask that participants take note \n",
    "of the following guidelines throughout the session:\n",
    "\n",
    "- This is an interactive workshop, and we expect everyone to follow along with the\n",
    "tutorial.\n",
    "- At the same time, please do not work ahead in the tutorial. If you are finished \n",
    "with a section ahead of time, you are more than welcome to hack away at our code.\n",
    "We find that staying together through the tutorial works best for everyone involved.\n",
    "- Hands on your own computer. Unless otherwise noted, please refrain from writing\n",
    "code on other's computers. You are more than welcome to explain to your neighbors\n",
    "what is going on in their notebook, but we want everyone to feel comfortable working\n",
    "with the code themselves. \n",
    "\n",
    "If you have any questions or concerns, please let us know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Goals\n",
    "\n",
    "We have a busy tutorial planned for today. At the end, we intend for you to be\n",
    "comfortable with the following tasks:\n",
    "\n",
    "- Read images into Python and display them\n",
    "- Organize a corpus of images and their metadata\n",
    "- Extract simple numeric features from images and use these to compare images\n",
    "- Apply pre-constructed neural networks to images in order to detect objects\n",
    "- Apply pre-constructed neural networks to images to produce more elaborate comparisons\n",
    "- Detect and identify faces in images\n",
    "- Build a set of webpages to explore a corpus of images and the above metrics\n",
    "\n",
    "Depending on our pace, we may not have time to finish all of these tasks, in which\n",
    "case you should be able to follow along on your own through the files provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Running code in an IPython notebook\n",
    "\n",
    "Below you will see a small snippet of python code. The first line \n",
    "prints out a welcome message and the second adds together two numbers.\n",
    "You can run them by clicking on the code block and hitting the \"Run\"\n",
    "button towards the top of this window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Welcome to Python!\")\n",
    "3 + 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can edit any of the code in this notebook. After clicking on the block\n",
    "just type and edit as you would do in any other online form, such as editing\n",
    "an email. **Change the code above to add together the numbers 3 and 10; rerun\n",
    "the block to print out the new answer.**\n",
    "\n",
    "Next, we need to load several python modules that provide functionalities that\n",
    "will be used throughout this tutorial. We will also set-up some default parameters\n",
    "that make the graphical output easier to look at. **Make sure you run this block\n",
    "of code prior to proceeding.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should run smoothly if you are using Anaconda Python version 3.5 or higher.\n",
    "If there are any errors, please raise your hand and let us know as soon as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Python arrays\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of what we need to do in Python concerning images will involve manipulating\n",
    "collections of numbers, known as arrays. We will not have time to give a full\n",
    "introduction to arrays, but here are some of the most important things to keep\n",
    "in mind.\n",
    "\n",
    "Here is a one-dimensional array, which is just a linear collection of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 2, 0, 7, 6, 9, 2, 8, 1, 0, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = np.array([4, 1, 2, 0, 7, 6, 9, 2, 8, 1, 0, 3])\n",
    "ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access a particular element in the array using a square bracket with the\n",
    "number of element we want to access. However, Python starts numbering things at\n",
    "zero. So to get the first element we need to write `ar[0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third element, similarly, can be accessed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write and run the code  in the box below that accesses the 7th element of the array\n",
    "(which is equal to 9)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays can also be a two-dimensional grid of numbers. For example,\n",
    "here is an array with three rows and four columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = np.array([4, 1, 2, 0, 7, 6, 9, 2, 8, 1, 0, 3]).reshape((3,4))\n",
    "ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access an element in two dimensions, we need to specify the row number,\n",
    "a comma, and then the column number. Again, Python starts at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar[1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can access a full row or column by using a colon `:`. It is\n",
    "interpreted as selecting every row/column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(ar[0, :])\n",
    "print(ar[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being familiar with this notation will be useful in the following code snippets, but\n",
    "you will not be required to write any array-based code from scratch so do not worry\n",
    "if this notation is new to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Images in Python\n",
    "\n",
    "We are now ready to read images into Python. We have several corpora that we\n",
    "will be working on in a few minutes, but for now let's just read in a test\n",
    "image I took of a teapot in my kitchen at home. To do this, we need to tell\n",
    "Python where the image is (its in a directory called 'test', which is inside\n",
    "a directory called 'images' and the file is called 'teapot.jpg'). Once we have\n",
    "the filename, we can read in the image into Python with the function `imread`\n",
    "as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(join(\"images\", \"test\", \"teapot.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now an object in python called `img` that contains all of the data that\n",
    "describes my image of a teapot. We can have Python print the image itself by \n",
    "calling the function `plt.imshow` on the image, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may not look like much, but trust me, it makes delicious tea.\n",
    "\n",
    "How exactly is Python storing the teapot image? Understanding the\n",
    "internal structure of an image object will be very important for\n",
    "today's tutorial. We can get some idea by looking at the `shape`\n",
    "property of the image object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that Python stores images as an array of numbers, but here the\n",
    "array has three dimensions. We can think of it as storing color images as\n",
    "three grids of numbers. These numbers tell Python the degree to which each\n",
    "pixel should be represented by red, green, and blue light. The shape above\n",
    "tells us that the image is 2016 pixels high and 1512 pixels wide. The third\n",
    "number reminds us that the image contains red, green, and blue pixels.\n",
    "\n",
    "We can print out the actual numbers in the image object, though looking at all\n",
    "of the numbers would be overwhelming. Let's took a slice of the `img` object\n",
    "from 1000-1010 vertical axis and 600-610 on the horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Red:\")\n",
    "print(img[1000:1010, 600:610, 0])\n",
    "\n",
    "print(\"Green:\")\n",
    "print(img[1000:1010, 600:610, 1])\n",
    "\n",
    "print(\"Blue:\")\n",
    "print(img[1000:1010, 600:610, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers in the image object range from 0 to 255. The higher the number the more\n",
    "that color shows up in a given pixel. If all three colors are 255 that would lead to\n",
    "a white pixel; all three equal to 0 gives a black pixel. \n",
    "\n",
    "Above, we see that the red pixels are larger than the green and blue. Does this make\n",
    "sense given the image of my teapot and the part of the image that we selected above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn.** Read in a similar photograph I took a bottle of Dickel Rye whiskey. \n",
    "Dickely Rye is an excellent alternative to tea in the evening hours, particularly\n",
    "if you are trying to avoid caffeine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(join(\"images\", \"test\", \"dickel.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block below, **write and execute the code to plot the new image**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy and re-run the code we used to see the amount of red, green, and blue pixels used\n",
    "in the middle of the photo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which color is the most dominant? Is it the one you would expect. How do\n",
    "these colors compare to the ones we saw for the teapot image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Describing images numerically\n",
    "\n",
    "As we saw, images in Python are represented by large tables of numbers. However, the\n",
    "values for an individual pixel are not particularly meaningful. It is only the image\n",
    "as a whole that holds a larger meaning to us. At the heart of this tutorial is finding\n",
    "ways to bridge the gap between numeric data and visual meaning. As a warning going \n",
    "forward: this is not an easy or entirely solved process, so do not get discourage by\n",
    "our first few attempts.\n",
    "\n",
    "We have already seen that we can make some sense of an image by looking at the relative\n",
    "amount of red, green, and blue pixels that it uses. We can't look at every single pixel,\n",
    "however. Another strategy would be to take the average of the three color channels. \n",
    "Reading the teapot image back in, we can see this with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(join(\"images\", \"test\", \"teapot.jpg\"))\n",
    "\n",
    "print(\"\\nRed mean:\")\n",
    "print(np.mean(img[:, :, 0]))\n",
    "        \n",
    "print(\"\\nGreen mean:\")\n",
    "print(np.mean(img[:, :, 1]))\n",
    "        \n",
    "print(\"\\nBlue mean:\")\n",
    "print(np.mean(img[:, :, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see that this shows that the teapot has a lot of the color\n",
    "red. How does this work for the bottle of Rye whiskey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(join(\"images\", \"test\", \"dickel.jpg\"))\n",
    "\n",
    "print(\"\\nRed mean:\")\n",
    "print(np.mean(img[:, :, 0]))\n",
    "        \n",
    "print(\"\\nGreen mean:\")\n",
    "print(np.mean(img[:, :, 1]))\n",
    "        \n",
    "print(\"\\nBlue mean:\")\n",
    "print(np.mean(img[:, :, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the amount of red has decreased and the amount of green has increased. However, we\n",
    "see that there is still a lot of all three colors here. Why is that? For one thing, the\n",
    "image has a lot of white in the background and all three colors need to light up for this\n",
    "to be visible. Because of this, the absolute intensity of each pixel is often not very\n",
    "useful on its own.\n",
    "\n",
    "As an alternative, let's compute a new table of numbers `img_maxcol` showing the maximum\n",
    "value of all the intensities for a given pixel. Similarly, we will compute `img_mincol`\n",
    "as the minimum color intensity for a pixel. Notice that these have the same number of row\n",
    "and columns as the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(join(\"images\", \"test\", \"teapot.jpg\"))\n",
    "\n",
    "img_maxcol = np.amax(img, 2)\n",
    "img_mincol = np.amin(img, 2)\n",
    "print(img_maxcol.shape)\n",
    "print(img_mincol.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a quantity called the *saturation*, which measures the richness of a color,\n",
    "as the difference between the maximum and minimum pixel intensities divided by the maximum\n",
    "intensitiy. Applying this to teapot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sat = (img_maxcol - img_mincol) / img_maxcol\n",
    "plt.imshow(img_sat, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows that the image is highly saturated on the body of the pot, but not very\n",
    "saturated in the white background. These should seem sensible when thinking \n",
    "about the definition we used for saturation. Let's also compute the mean saturation\n",
    "of the image as we did for the average value of the pixel intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(img_sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see in the next section that the average saturation is a reasonable measurement for\n",
    "comparing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Working with image corpora\n",
    "\n",
    "It is now time to start working with the large collections of images that we have\n",
    "gathered. We will start working together on the corpus of paintings. You'll have\n",
    "a chance to work with the other collections shortly.\n",
    "\n",
    "To start, we will load a metadata table with information about each of the images \n",
    "in the corpus. Run the following line and scroll through the images to get a sense\n",
    "of the collection and the available metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiart = pd.read_csv(\"meta/wikiart.csv\")\n",
    "wikiart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can read in an image in the corpus and print it, just as we did with the test images.\n",
    "Here, we will load the 201st image in the corpus and print the image itself. We will also\n",
    "print out the metadata about the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = join('images', 'wikiart', wikiart['filename'][200])\n",
    "print(wikiart.iloc[200])\n",
    "\n",
    "img = imread(img_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the code from the block above, and select a different image from the corpus. There\n",
    "are 645 images, so select any number from 0 to 644."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to do something with the entire corpus together. We will add two\n",
    "new columns to the dataset called `red` and `saturation`. For each image, we\n",
    "will record the average intensity of these two measurements.\n",
    "\n",
    "To fill these values in for each image, we will make use of a `for` loop. Within\n",
    "the loop, we simply apply the code we have used above to compute the red and\n",
    "saturation values. This might take a minutes or two to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = np.zeros(wikiart.shape[0])\n",
    "sat = np.zeros(wikiart.shape[0])\n",
    "\n",
    "for index, row in wikiart.iterrows():\n",
    "    img_path = join('images', 'wikiart', row['filename'])\n",
    "    img = imread(img_path)\n",
    "    img_maxcol = np.amax(img, 2)\n",
    "    img_maxcol[img_maxcol == 0] = 1\n",
    "    img_mincol = np.amin(img, 2)\n",
    "    img_sat = (img_maxcol - img_mincol) / img_maxcol\n",
    "    \n",
    "    red[index] = np.mean(img[:, :, 0])\n",
    "    sat[index] = np.mean(img_sat) \n",
    "    if index % 100 == 0:\n",
    "        print(\"Done with {0:d}\".format(index))\n",
    "\n",
    "    \n",
    "wikiart[\"red\"] = red\n",
    "wikiart[\"saturation\"] = sat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that these have been added to the dataset `wikiart` by printing it\n",
    "out once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualizing \n",
    "\n",
    "We have done all of this work in order to produce metrics that describe the images\n",
    "in a way that allows us to visualize the corpus. We want, in this case, to organize\n",
    "images such that those with a similar usage of red and saturation are grouped together.\n",
    "\n",
    "For example, take the saturation and red values of each image colored by painter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 14))\n",
    "\n",
    "cmap = {'Morisot Berthe': 'olive', 'Rivera Diego': 'pink', 'Monet Claude': 'navy'}\n",
    "wikiart.plot(x='red', y='saturation', kind='scatter', \n",
    "             color=[cmap.get(c, 'black') for c in wikiart.artist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any interesting patterns here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing that we can do is to look at images that have the lowest saturation\n",
    "and see how these relate to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "sat_index = np.argsort(wikiart['saturation']).tolist()\n",
    "for ind, i in enumerate(sat_index[:24]):\n",
    "    try:\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.subplot(4, 6, ind + 1)\n",
    "\n",
    "        img_path = join('images', 'wikiart', wikiart.iloc[i]['filename'])\n",
    "        img = imread(img_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's redo this but take those images with the highest saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "sat_index = np.argsort(wikiart['saturation']).tolist()\n",
    "for ind, i in enumerate(sat_index[-24:]):\n",
    "    try:\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.subplot(4, 6, ind + 1)\n",
    "\n",
    "        img_path = join('images', 'wikiart', wikiart.iloc[i]['filename'])\n",
    "        img = imread(img_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you categorize the differences between the images in the high and low\n",
    "saturation groups? Does this metric seem to cluster together, at least on the\n",
    "extreme, similar images?\n",
    "\n",
    "Now let's take a particular image and show all of the other images with a similar\n",
    "saturation. Here, we are using the top-left image as a starting point and finding\n",
    "the 23 other images that are most similar to it by saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "X = np.array(wikiart['saturation'].tolist()).reshape((wikiart.shape[0],1))\n",
    "\n",
    "idx = np.argsort(np.abs(X - X[1, :]).flatten())[:24]\n",
    "\n",
    "for ind, i in enumerate(idx):\n",
    "    try:\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.subplot(4, 6, ind + 1)\n",
    "\n",
    "        img_path = join('images', 'wikiart', wikiart.iloc[i]['filename'])\n",
    "        img = imread(img_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, these images are not particularly similar in any consistent way. \n",
    "Saturation is a good similarity score at its extreme values (white, faded backgrounds\n",
    "on one end and bright murals on the other). It is not a great general purpose measurement.\n",
    "We need a more complex measurement!\n",
    "\n",
    "**Copy the code above, but use a different starting image.** Do the recommendations for this\n",
    "image look better, worse, or about the same as the those for the image we used above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) Step 8: FSA-OWI Photographs \n",
    "\n",
    "The set of data in this repository contains three sets of image corpora. One nice\n",
    "aspect of the code we have introduced is that it can be easily adapted to work with\n",
    "another set of images stored in a similar format. Here, we will look at a subset of\n",
    "the FSA-OWI collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and modify the appropriate code above to read in the `fsa_owi.csv` file. Copy it below,\n",
    "read in the dataset, and look at the head of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block below, print out the 100th image in the FSA-OWI corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the FSA-OWI images are in black and white. This means that the red, blue, and green\n",
    "pixel intensites are all the same. High values are more white and low values are more black.\n",
    "Cycle over the corpus and add a measurement of the red pixel intensities to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write and execute the code to display the 24 images that are the darkest, that is, they have\n",
    "the lowest average red pixel intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat with the lightest images, those with the highest average red intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does the average pixel intensity cluster similar images together at the extreme values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
