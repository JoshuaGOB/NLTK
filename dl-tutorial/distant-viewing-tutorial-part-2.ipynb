{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distant Viewing with Deep Learning: Part 2\n",
    "\n",
    "In Part 2 of this tutorial, we introduce the concepts of deep learning and show it yields\n",
    "interesting similarity metrics and is able to extract feature useful features such as the\n",
    "presence and location of faces in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Python modules for deep learning\n",
    "\n",
    "We need to reload all of the Python modules we used in the Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import importlib\n",
    "import os\n",
    "from os.path import join\n",
    "from matplotlib.colors import rgb_to_hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to reload the wikiart metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiart = pd.read_csv(\"meta/wikiart.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the code in this notebook from scratch, you will also need the **keras**\n",
    "module for working with neural networks. This are not included in the default\n",
    "Anaconda Python installation and need to be installed seperately. The code\n",
    "below checks if you have keras installed. If you do, it will be loaded. Otherwise,\n",
    "a flag will be set so that the code below that requires keras will load the\n",
    "pre-loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if importlib.util.find_spec(\"keras\") is not None:\n",
    "    from keras.applications.vgg19 import VGG19\n",
    "    from keras.preprocessing import image\n",
    "    from keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "    from keras.models import Model\n",
    "    keras_flag = True\n",
    "else:\n",
    "    keras_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are struggling with installing these, we are happy to assist. You'll be able to follow\n",
    "along without keras, but will not be able to apply the techniques you learned today to new datasets\n",
    "without it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Applying deep learning with neural networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading a particular neural network model called VGG19. It\n",
    "contains 25 layers and over 143 million parameters. The code below reads\n",
    "in the entire model and prints out it structure (unless keras is unavailable,\n",
    "in which case a saved version of the model is printed just for reference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if keras_flag:\n",
    "    vgg19_full = VGG19(weights='imagenet')\n",
    "    vgg19_full.summary()\n",
    "else:\n",
    "    with open('data/vgg19.txt','r') as f:\n",
    "        for line in f:\n",
    "            print(line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The VGG19 model was trained to identify 1000 classes of objects within an\n",
    "image. It was built as part of the ImageNet challenge, one of the most\n",
    "influential computer vision competitions that has been running since 2010.\n",
    "\n",
    "We will load a test photo of my dog and see what classes the model predicts\n",
    "for the image. We will use a slightly different function to read in the image\n",
    "that scales it to have 224-by-224 pixels as required by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = join(\"images\", \"test\", \"dog.jpg\")\n",
    "if keras_flag:\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "else:\n",
    "    img = imread(img_path)\n",
    "    x = img.copy().astype(np.float32)\n",
    "    \n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it is now a four dimensional array, a point that we will come back to in\n",
    "a moment. We can look at the image here using the `imshow` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have keras installed, the code here takes the image `x` and predicts\n",
    "values from the model. Notice that the output of the model is a sequence of 1000\n",
    "numbers. These indicate the predicted probability that the image contains each of \n",
    "one of the 1000 pre-selected categories. The function `decode_predictions` converts\n",
    "these to give the names of the five most likely categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if keras_flag:\n",
    "    y = vgg19_full.predict(x)\n",
    "    print(y.shape)\n",
    "    for pred in decode_predictions(y)[0]:\n",
    "        print(pred)\n",
    "else:\n",
    "    print((1, 1000))\n",
    "    y = np.load(join('data', 'dog_pred.npy'))\n",
    "    for pred in decode_predictions(y)[0]:\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest predicted class is a \"Shih-Tzu\", incidently an exact match for his\n",
    "breed! The other dogs are all similarly sized dogs, and obvious choices for \n",
    "making a mistake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute the category predictions for each image in the corpus. This involves\n",
    "reading in each image in the wikiart corpus and then running them through the VGG19\n",
    "model. This can take some time, particularly on an older machine, so we have created a\n",
    "flag called `process_new`. Keep it to `False` to load pre-computed categories; you can\n",
    "switch it to `True` if you want to compute them directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_new = False\n",
    "\n",
    "if process_new:\n",
    "    wikiart_img = np.zeros((wikiart.shape[0], 224, 224, 3))\n",
    "\n",
    "    for index, row in wikiart.iterrows():\n",
    "        img_path = join('images', 'wikiart', row['filename'])\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        wikiart_img[index, :, :, :] = x\n",
    "        if (index % 50) == 0:\n",
    "            print(\"Done with {0:03d}\".format(index))\n",
    "        \n",
    "    wikiart_img = preprocess_input(wikiart_img)\n",
    "    wikiart_raw = vgg19_full.predict(wikiart_img, verbose=True)\n",
    "    wikiart_vgg19 = decode_predictions(wikiart_raw, top=20)\n",
    "    \n",
    "else:\n",
    "    wikiart_vgg19 = np.load(\"data/wikiart_vgg19_categories.npy\")\n",
    "\n",
    "print(wikiart_vgg19.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the most common top category type for this collection? When can use the\n",
    "Python module `collections` to look at the top-10 most common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections.Counter(wikiart_vgg19[:, 1, 1]).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliffs and fountains both seem reasonable, but I doubt there are many jigsaw puzzels \n",
    "in the wikiart corpus. **Any idea by this might be so common?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Neural network embedding\n",
    "\n",
    "The VGG19 model was constructed in order to predict the objects present in an image,\n",
    "but there is a lot more that we can do with the model. The amazing property of deep\n",
    "learning is that the intermediate results in the neural network operate by detecting\n",
    "lower-level features of the image. For example, the first few detect edges and textures,\n",
    "the next few by understanding shapes, and the latter ones put these together to detect\n",
    "objects. This is incredibly useful because it means that looking at the intermediate\n",
    "outputs can tell us something interesting about the images beyond just the 1000\n",
    "predicted categories.\n",
    "\n",
    "Assuming the keras module is installed, we will create a new model that outputs the\n",
    "second-to-last output of the model. The prediction of this contains 4096 dimensions.\n",
    "These do not correspond directly to categories, but (in theory) images containing\n",
    "similar objects should have similar 4096-dimensional values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if keras_flag:\n",
    "    vgg_fc2 = Model(inputs=vgg19_full.input, outputs=vgg19_full.get_layer('fc2').output)\n",
    "    y = vgg_fc2.predict(x)\n",
    "    print(y.shape)\n",
    "else:\n",
    "    print((1, 4096))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this new model to predict values on the set of images `wikiart_img`. As above,\n",
    "this can take a few minutes, so you may want to load the pre-saved data again by keeping\n",
    "`process_new` equal to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_new = False\n",
    "\n",
    "if process_new:\n",
    "    wikiart_fc2 = vgg_fc2.predict(wikiart_img, verbose=True)\n",
    "    wikiart_fc2.shape\n",
    "else:\n",
    "    wikiart_fc2 = np.load(\"data/wikiart_vgg19_fc2.npy\")\n",
    "\n",
    "print(wikiart_fc2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use these values to figure out which images are similar to another image.\n",
    "This is similar to the closest saturation values, but using a more complex numeric\n",
    "metric for comparison. Compare the results here with those from saturation alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "dists = np.sum(np.abs(wikiart_fc2 - wikiart_fc2[1, :]), 1)\n",
    "idx = np.argsort(dists.flatten())[:12]\n",
    "\n",
    "for ind, i in enumerate(idx):\n",
    "    try:\n",
    "        plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "        plt.subplot(3, 4, ind + 1)\n",
    "\n",
    "        img_path = join('images', 'wikiart', wikiart.iloc[i]['filename'])\n",
    "        img = imread(img_path)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are all impressionist paintings of trees, showing how the model matches both the\n",
    "content and style of the original. **In the code below, look at the recommendations for the\n",
    "image you used back in part 7.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
